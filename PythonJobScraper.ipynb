{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOb9ERoL/bHg7Dx3xt9mzZ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aami78/PythonJobScraper/blob/main/PythonJobScraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4\n",
        "!pip install pymongo[srv]\n",
        "import requests\n",
        "import json\n",
        "\n",
        "url='https://in.indeed.com/jobs?q=python+developer'\n",
        "username = 'agni_mithra'\n",
        "apiKey = '7exRkYFSxfUcFrmnQ73BdmsbC'\n",
        "\n",
        "apiEndPoint = \"http://api.scraping-bot.io/scrape/raw-html\"\n",
        "\n",
        "options = {\n",
        "    \"useChrome\": True,#set to True if you want to use headless chrome for javascript rendering\n",
        "    \"premiumProxy\": True, # set to True if you want to use premium proxies Unblock Amazon,Google,Rakuten\n",
        "    \"proxyCountry\": None, # allows you to choose a country proxy (example: proxyCountry:\"FR\")\n",
        "    \"waitForNetworkRequests\":True # wait for most ajax requests to finish until returning the Html content (this option can only be used if useChrome is set to true),\n",
        "                                   # this can slowdown or fail your scraping if some requests are never ending only use if really needed to get some price loaded asynchronously for example\n",
        "}\n",
        "\n",
        "payload = json.dumps({\"url\":url,\"options\":options})\n",
        "headers = {\n",
        "    'Content-Type': \"application/json\"\n",
        "}\n",
        "\n",
        "response = requests.request(\"POST\", apiEndPoint, data=payload, auth=(username,apiKey), headers=headers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZu0Ht9XrId6",
        "outputId": "f5ecbee4-76b1-4fd6-80ab-f87a59a275ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Collecting pymongo[srv]\n",
            "  Using cached pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo[srv])\n",
            "  Using cached dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "Installing collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.4.2 pymongo-4.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pymongo\n",
        "from pymongo import MongoClient\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Replace with your connection string\n",
        "conn_str = 'mongodb+srv://aamipalakkal:QW39YEMqxD9C7Pzr@cluster0.865ainc.mongodb.net/?retryWrites=true&w=majority'\n",
        "\n",
        "# Connect to your MongoDB cluster\n",
        "client = MongoClient(conn_str)\n",
        "db = client['job_listings']  # Create a database called 'job_listings'\n",
        "collection = db['listings']  # Create a collection called 'listings'\n",
        "\n",
        "\n",
        "# Find all job listing items\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "job_listings = soup.find_all('li', class_='css-5lfssm')\n",
        "\n",
        "for job in job_listings:\n",
        "    # Extract the job title\n",
        "    title_tag = job.find('h2', class_='jobTitle')\n",
        "    title = title_tag.get_text(strip=True) if title_tag else 'N/A'\n",
        "\n",
        "    # Extract the company name\n",
        "    company_tag = job.find('span', {'data-testid': 'company-name'})\n",
        "    company = company_tag.get_text(strip=True) if company_tag else 'N/A'\n",
        "\n",
        "    # Extract the location\n",
        "    location_tag = job.find('div', {'data-testid': 'text-location'})\n",
        "    location = location_tag.get_text(strip=True) if location_tag else 'N/A'\n",
        "    print(f\"Job Title: {title}, Company: {company}, Location: {location}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndCp6ZsIZQlf",
        "outputId": "e9f70400-4c90-4480-a79f-7333a30db227"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job Title: Python Developer - C10, Company: Citi, Location: Gurgaon, Haryana\n",
            "Job Title: Developer - FullStack (Python), Company: Airbus, Location: Bengaluru, Karnataka\n",
            "Job Title: Python Developer Jobs (USA), Company: Sanfoundry, Location: Bengaluru, Karnataka\n",
            "Job Title: Python Developer, Company: A2Z Jobs Consultancy, Location: Chennai, Tamil Nadu\n",
            "Job Title: Python Developer, Company: Splice Global Services, Location: Remote\n",
            "Job Title: N/A, Company: N/A, Location: N/A\n",
            "Job Title: Python Developer (Remote), Company: Assistnow Inc, Location: Remote in Chennai, Tamil Nadu\n",
            "Job Title: Python Developer, Company: Artoon Solutions Pvt. Ltd., Location: Varachha, Surat, Gujarat\n",
            "Job Title: Python Senior Developer, Company: Infosys, Location: Bengaluru, Karnataka\n",
            "Job Title: Python Developer (Ahmedabad), Company: Uplers, Location: Ahmedabad, Gujarat\n",
            "Job Title: Python Django Developer, Company: ZOG Global, Location: Remote\n",
            "Job Title: N/A, Company: N/A, Location: N/A\n",
            "Job Title: Python Developer, Company: Marktine Technology Solutions, Location: Bengaluru, Karnataka\n",
            "Job Title: Python Developer, Company: Gritstone Technologies, Location: Calicut, Kerala\n",
            "Job Title: Python Java Developer, Company: Virtusa, Location: Hybrid remote in Bengaluru, Karnataka\n",
            "Job Title: Python (Programming Language) Application Developer, Company: Accenture, Location: Pune, Maharashtra\n",
            "Job Title: Python and D-Jango Developer | Exp 1 - 2 years | Mumbai, Company: Rentokil, Location: India\n",
            "Job Title: N/A, Company: N/A, Location: N/A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install requests beautifulsoup4\n"
      ],
      "metadata": {
        "id": "LOQiOnYO4GUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac4f31c-4b7b-4c58-986f-4f7468b0f0a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.11.17)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Your specified URL\n",
        "url = 'https://in.indeed.com/jobs?q=python+developer&l=Kochi'\n",
        "\n",
        "# Your authentication details\n",
        "username = 'aami'\n",
        "apiKey = 'c2mFKVqwogKiQ3PIbaagDllDL'\n",
        "\n",
        "# API endpoint and options\n",
        "apiEndPoint = \"http://api.scraping-bot.io/scrape/raw-html\"\n",
        "options = {\n",
        "    \"useChrome\": True,\n",
        "    \"premiumProxy\": True,\n",
        "    \"proxyCountry\": None,\n",
        "    \"waitForNetworkRequests\": True,\n",
        "}\n",
        "\n",
        "# Prepare the payload\n",
        "payload = json.dumps({\"url\": url, \"options\": options})\n",
        "headers = {'Content-Type': \"application/json\"}\n",
        "\n",
        "# Make the request\n",
        "response = requests.request(\"POST\", apiEndPoint, data=payload, auth=(username, apiKey), headers=headers)\n",
        "print(response)\n",
        "# Parse the response\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find all job listing items\n",
        "job_listings = soup.find_all('li', class_='css-5lfssm')\n",
        "\n",
        "for job in job_listings:\n",
        "    # Extract the salary\n",
        "    salary_tag = job.find('div', class_='css-1ihavw2 eu4oa1w0', string=lambda text: \"₹\" in text )\n",
        "    salary = salary_tag.get_text(strip=True) if salary_tag else 'Salary not listed'\n",
        "\n",
        "    print(f\"Salary: {salary}\")\n"
      ],
      "metadata": {
        "id": "e6K8F360ZCo3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d45bd9-4584-415d-fbfd-ad79e4cfb547"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [403]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install numpy\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def process_salary(salary_str):\n",
        "    # Remove currency symbols and split by non-numeric characters\n",
        "    salary_str = salary_str.replace('₹', '').replace(',', '').strip()\n",
        "    parts = [s.strip() for s in salary_str.split() if s.isdigit()]\n",
        "\n",
        "    if not parts:\n",
        "        return None\n",
        "\n",
        "    # Convert parts to integers\n",
        "    numbers = list(map(int, parts))\n",
        "\n",
        "    # Calculate average if it's a range, otherwise return the number\n",
        "    return sum(numbers) / len(numbers) if len(numbers) > 1 else numbers[0]\n",
        "\n",
        "# Example usage\n",
        "salaries = []\n",
        "for job in job_listings:\n",
        "    salary_tag = job.find('div', class_='css-1ihavw2 eu4oa1w0', string=lambda text: \"₹\" in text)\n",
        "    if salary_tag:\n",
        "        processed_salary = process_salary(salary_tag.get_text(strip=True))\n",
        "        if processed_salary:\n",
        "            salaries.append(processed_salary)\n",
        "\n",
        "# Convert list to NumPy array for easy calculations\n",
        "import numpy as np\n",
        "salaries_array = np.array(salaries)\n",
        "\n",
        "# Calculate the average salary\n",
        "average_salary = np.mean(salaries_array) if salaries_array.size > 0 else 0\n",
        "\n",
        "print(f\"Average Salary: ₹{average_salary:.2f}\")\n"
      ],
      "metadata": {
        "id": "RRbj4fahyi34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec1ab41-0ba5-4ebc-e2d9-dc16ab8b64e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Average Salary: ₹494000.00\n"
          ]
        }
      ]
    }
  ]
}